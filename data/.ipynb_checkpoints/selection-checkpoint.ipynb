{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd989e2e-79b5-4a3b-bc2f-21e366baeb73",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Full_Data -> sequntial ë³€í™˜\n",
    "- full_data: (ì›¹íˆ°ì±…1ê¶Œ~4ê¶Œê¹Œì§€ == ì• ë‹ˆë©”ì´ì…˜ ê¸°ì¤€ 1ê¸°) - íŠ¹ì • ì—í”¼ì†Œë“œ 3ê°œ ì œì™¸í•œ ê²ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c09c0d9c-77b1-4640-9ce7-43d97b16f0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë³€í™˜, ì €ì¥ ìœ„ì¹˜: sl_webtoon_full_data_sequential.tsv\n",
      "         ì—í”¼ì†Œë“œ                     scene_text  type\n",
      "0  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „    ë„¤, ê¹€ìƒì‹ ì•„ì €ì”¨. ì‹ ê²½ ì¨ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.    ëŒ€ì‚¬\n",
      "1  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „               ë‚´ ì´ë¦„ì€ ì„±ì§„ìš°. Eê¸‰ í—Œí„°  ë‚´ì ì„¤ëª…\n",
      "2  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „         ë­˜ìš” í•˜í•˜... ì˜¤ëŠ˜ë„ ì˜ ë¶€íƒë“œë¦´ê²Œìš”.    ëŒ€ì‚¬\n",
      "3  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „    í—Œí„°í˜‘íšŒ ì†Œì† ì¤‘ ê°€ì¥ ë‚®ì€ ê³„ê¸‰, ìµœì•½ì˜ í—Œí„°.  ë‚´ì ì„¤ëª…\n",
      "4  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „  ì–´? ì•ˆë…•í•˜ì„¸ìš”. ì£¼í¬ ì”¨ë„ ì´ë²ˆ ë ˆì´ë“œ ê°€ì‹œëŠ”êµ°ìš”.    ëŒ€ì‚¬\n",
      "5  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „   ë‚˜ì—ê²Œ ì´ëŸ° ì¼ì´ ì¼ì–´ë‚  ì¤„ì€...ìƒìƒë„ ëª» í–ˆë‹¤.  ë‚´ì ì„¤ëª…\n",
      "6  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „            ì–´ì©Œë‹¤ë³´ë‹ˆ ê·¸ë ‡ê²Œ ëë„¤ìš” í•˜í•˜...    ëŒ€ì‚¬\n",
      "7  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „                        ëŒ€í•œë¯¼êµ­ ì„œìš¸  ë‚´ì ì„¤ëª…\n",
      "8  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „         Eê¸‰ ë˜ì „ì´ì—ˆëŠ”ë° ì €ë§Œ ë‹¤ì³ì„œ ë‚˜ì™”ì–´ìš”.    ëŒ€ì‚¬\n",
      "9  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „                     Eê¸‰ í—Œí„° ì„±ì§„ìš°.  ë‚´ì ì„¤ëª…\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_path = \"sl_webtoon_full_data.tsv\"\n",
    "output_path = \"sl_webtoon_full_data_sequential.tsv\"\n",
    "\n",
    "df = pd.read_csv(input_path, sep='\\t', encoding='utf-8')\n",
    "\n",
    "df = df.fillna(\"\") #ê²°ì¸¡ì¹˜ \"\" ë¡œ ë³€í™˜\n",
    "\n",
    "cols = ['ì—í”¼ì†Œë“œëª…', 'ëŒ€ì‚¬', 'ë‚´ì ì„¤ëª…', 'ì‹œìŠ¤í…œ']0\n",
    "\n",
    "rows = []\n",
    "for ep, group in df.groupby('ì—í”¼ì†Œë“œëª…'):\n",
    "    for idx, row in group.iterrows():\n",
    "        for col in ['ëŒ€ì‚¬', 'ë‚´ì ì„¤ëª…', 'ì‹œìŠ¤í…œ']:\n",
    "            text = row[col].strip()\n",
    "            if text:  \n",
    "                rows.append({\n",
    "                    'ì—í”¼ì†Œë“œ': ep,\n",
    "                    'scene_text': text,\n",
    "                    'type': col  \n",
    "                })\n",
    "\n",
    "seq_df = pd.DataFrame(rows)\n",
    "\n",
    "seq_df.to_csv(output_path, sep='\\t', index=False, encoding='utf-8')\n",
    "\n",
    "print(\"ë³€í™˜, ì €ì¥ ìœ„ì¹˜:\", output_path)\n",
    "print(seq_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484907bd-15ea-4536-8f85-71104ef1ac9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7f841c6-ba70-45ee-970e-98199090275e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìœ ì‚¬ ì¥ë©´ Top 10 \n",
      "\n",
      "[ì ìˆ˜: 83.3571] 1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „ ë‚´ ì´ë¦„ì€ ì„±ì§„ìš°. Eê¸‰ í—Œí„° ë‚´ì ì„¤ëª…\n",
      "[ì ìˆ˜: 88.2755] 2ê¶Œ_4í™”_ë³´ìŠ¤ì „ í—Œí„° ì„±ì§„ìš°ì…ë‹ˆë‹¤. ëŒ€ì‚¬\n",
      "[ì ìˆ˜: 93.2208] 1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „ Eê¸‰ í—Œí„° ì„±ì§„ìš°. ë‚´ì ì„¤ëª…\n",
      "[ì ìˆ˜: 99.7465] 3ê¶Œ_7í™”_ì´ìƒí•œë ˆì´ë“œ ê·¸ ë…€ì„ì´ ì›í•˜ëŠ” ê±´ ì‹¤ë ¥ì€ ìˆì§€ë§Œ ë“±ê¸‰ì´ ë‚®ì€ í—Œí„°ë‹ˆê¹Œ. ë‚´ì ì„¤ëª…\n",
      "[ì ìˆ˜: 102.8061] 3ê¶Œ_7í™”_ì´ìƒí•œë ˆì´ë“œ Sê¸‰ í—Œí„°ì¸ í™©ë™ìˆ˜ë¥¼ ë§í•˜ëŠ” ê²ë‹ˆê¹Œ? ëŒ€ì‚¬\n",
      "[ì ìˆ˜: 109.0561] 2ê¶Œ_4í™”_ë³´ìŠ¤ì „ ëŠ¥ë ¥ì¹˜ë¥¼ ì˜¬ë¦´ ìˆ˜ ìˆëŠ” í—Œí„°ê°€ ìˆë‹¤? ë‚´ì ì„¤ëª…\n",
      "[ì ìˆ˜: 109.9106] 1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „ í—Œí„°í˜‘íšŒ ì†Œì† ì¤‘ ê°€ì¥ ë‚®ì€ ê³„ê¸‰, ìµœì•½ì˜ í—Œí„°. ë‚´ì ì„¤ëª…\n",
      "[ì ìˆ˜: 110.5650] 2ê¶Œ_2í™”_ì„¸ê°€ì§€ê·œìœ¨ ì—¬ê¸°ì„œ ê¸°ë‹¤ë¦¬ê³  ìˆìœ¼ë©´ ë‹¤ë¥¸ í—Œí„°ë“¤ì´ êµ¬ì¡°í•˜ëŸ¬ ì˜¬ê¹Œìš”? ëŒ€ì‚¬\n",
      "[ì ìˆ˜: 114.7391] 1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „ ëª©ìˆ¨ì„ ê±°ëŠ” ìœ„í—˜í•œ ì§ì—… 'í—Œí„°'. ë‚˜ë¼ê³  ì¢‹ì•„ì„œ ì´ ì¼ì„ í•˜ëŠ” ê±´ ì•„ë‹ˆë‹¤. ë‚´ì ì„¤ëª…\n",
      "[ì ìˆ˜: 119.2824] 1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „ ê³ ì¡¸ ì¶œì‹ ì— ë”±íˆ ì˜í•˜ëŠ” ê²ƒë„ ì—†ëŠ” ë‚´ê²Œ, í—Œí„°ë¼ëŠ” ì§ì—…ì€ í”¼í•  ìˆ˜ ì—†ëŠ” ì„ íƒì´ì—ˆë‹¤. ë‚´ì ì„¤ëª…\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "index = faiss.read_index(\"solo_leveling_faiss_ko.index\")\n",
    "with open(\"solo_leveling_texts.pkl\", \"rb\") as f:\n",
    "    texts = pickle.load(f)\n",
    "\n",
    "model = SentenceTransformer('jhgan/ko-sroberta-multitask')\n",
    "\n",
    "query = \"ì„±ì§„ìš°ëŠ” ëª‡ ê¸‰ í—Œí„°?\"\n",
    "\n",
    "query_vec = model.encode([query])\n",
    "D, I = index.search(query_vec, k=10)  # ìƒìœ„ 5ê°œ\n",
    "\n",
    "print(\"ìœ ì‚¬ ì¥ë©´ Top 10 \\n\")\n",
    "for idx, score in zip(I[0], D[0]):\n",
    "    print(f\"[ì ìˆ˜: {score:.4f}] {texts[idx]}\")\n",
    "#ì ìˆ˜ ë‚®ì„ ìˆ˜ë¡ ìœ ì‚¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a758d87-767b-43d6-b9fe-957b405d6f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] [1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #1 ë‚´ì ì„¤ëª… ë‚´ ì´ë¦„ì€ ì„±ì§„ìš°. Eê¸‰ í—Œí„°\n",
      "[2] [3ê¶Œ_7í™”_ì´ìƒí•œë ˆì´ë“œ] #487 ëŒ€ì‚¬ Sê¸‰ í—Œí„°ì¸ í™©ë™ìˆ˜ë¥¼ ë§í•˜ëŠ” ê²ë‹ˆê¹Œ?\n",
      "[3] [1ê¶Œ_3í™”_í€˜ìŠ¤íŠ¸] #91 ëŒ€ì‚¬ ì£¼í¬ ì”¨ë‚˜ ì†¡ì¹˜ì—´ ì•„ì €ì”¨ëŠ” ì–´ë–»ê²Œ ë˜ì…¨ì£ ?\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The de-serialization relies loading a pickle file. Pickle files can be modified to deliver a malicious payload that results in execution of arbitrary code on your machine.You will need to set `allow_dangerous_deserialization` to `True` to enable deserialization. If you do this, make sure that you trust the source of the data. For example, if you are loading a file that you created, and know that no one else has modified the file, then this is safe to do. Do not set this to `True` if you are loading a file from an untrusted source (e.g., some random site on the internet.).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# 1. ë²¡í„° DB ë¡œë“œ\u001b[39;00m\n\u001b[1;32m     21\u001b[0m embedding \u001b[38;5;241m=\u001b[39m HuggingFaceEmbeddings(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjhgan/ko-sroberta-multitask\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_local\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msolo_leveling_faiss_ko\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 2. ì˜ˆì‹œ ì§ˆì˜\u001b[39;00m\n\u001b[1;32m     25\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mì„±ì§„ìš°ëŠ” í™©ë™ì„ê³¼ ì²˜ìŒ ë§Œë‚œ ì¥ë©´ì—ì„œ ë¬´ì—‡ì„ í–ˆì–´?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_community/vectorstores/faiss.py:1190\u001b[0m, in \u001b[0;36mFAISS.load_local\u001b[0;34m(cls, folder_path, embeddings, index_name, allow_dangerous_deserialization, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load FAISS index, docstore, and index_to_docstore_id from disk.\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m \n\u001b[1;32m   1178\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;124;03m        arbitrary code on your machine.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_dangerous_deserialization:\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe de-serialization relies loading a pickle file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1192\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPickle files can be modified to deliver a malicious payload that \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults in execution of arbitrary code on your machine.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou will need to set `allow_dangerous_deserialization` to `True` to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable deserialization. If you do this, make sure that you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust the source of the data. For example, if you are loading a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile that you created, and know that no one else has modified the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile, then this is safe to do. Do not set this to `True` if you are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1199\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading a file from an untrusted source (e.g., some random site on \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1200\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe internet.).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1201\u001b[0m     )\n\u001b[1;32m   1202\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(folder_path)\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;66;03m# load index separately since it is not picklable\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The de-serialization relies loading a pickle file. Pickle files can be modified to deliver a malicious payload that results in execution of arbitrary code on your machine.You will need to set `allow_dangerous_deserialization` to `True` to enable deserialization. If you do this, make sure that you trust the source of the data. For example, if you are loading a file that you created, and know that no one else has modified the file, then this is safe to do. Do not set this to `True` if you are loading a file from an untrusted source (e.g., some random site on the internet.)."
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import pickle\n",
    "\n",
    "# 1. ë²¡í„° DB ë¡œë“œ\n",
    "embedding = HuggingFaceEmbeddings(model_name='jhgan/ko-sroberta-multitask')\n",
    "db = FAISS.load_local(\"solo_leveling_faiss_ko\", embedding, allow_dangerous_deserialization=True)  # ğŸ”¹ ì´ ì˜µì…˜ ì¶”ê°€\n",
    "\n",
    "\n",
    "# 2. ì˜ˆì‹œ ì§ˆì˜\n",
    "query = \"ì„±ì§„ìš°ëŠ” í™©ë™ì„ê³¼ ì²˜ìŒ ë§Œë‚œ ì¥ë©´ì—ì„œ ë¬´ì—‡ì„ í–ˆì–´?\"\n",
    "docs = db.similarity_search(query, k=3)\n",
    "\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"[{i}] {doc.page_content}\")\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import pickle\n",
    "\n",
    "# 1. ë²¡í„° DB ë¡œë“œ\n",
    "embedding = HuggingFaceEmbeddings(model_name='jhgan/ko-sroberta-multitask')\n",
    "db = FAISS.load_local(\"solo_leveling_faiss_ko\", embedding)\n",
    "\n",
    "# 2. ì˜ˆì‹œ ì§ˆì˜\n",
    "query = \"ì„±ì§„ìš°ëŠ” í™©ë™ì„ê³¼ ì²˜ìŒ ë§Œë‚œ ì¥ë©´ì—ì„œ ë¬´ì—‡ì„ í–ˆì–´?\"\n",
    "docs = db.similarity_search(query, k=3)\n",
    "\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"[{i}] {doc.page_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac05aed2-9dae-4f2f-b3a1-eee03a1f5c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.in_memory import InMemoryDocstore\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import faiss\n",
    "import pickle\n",
    "\n",
    "# 1. ê¸°ì¡´ ë°ì´í„° ë¡œë“œ\n",
    "index_path = \"solo_leveling_faiss_ko.index\"\n",
    "texts_path = \"solo_leveling_texts.pkl\"\n",
    "\n",
    "index = faiss.read_index(index_path)\n",
    "with open(texts_path, \"rb\") as f:\n",
    "    texts = pickle.load(f)\n",
    "\n",
    "# 2. ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„\n",
    "embedding = HuggingFaceEmbeddings(model_name='jhgan/ko-sroberta-multitask')\n",
    "\n",
    "# 3. LangChain ë¬¸ì„œí™”\n",
    "docs = [Document(page_content=text) for text in texts]\n",
    "docstore = InMemoryDocstore({str(i): doc for i, doc in enumerate(docs)})\n",
    "index_to_docstore_id = {i: str(i) for i in range(len(docs))}\n",
    "\n",
    "db = FAISS(\n",
    "    embedding_function=embedding,\n",
    "    index=index,\n",
    "    docstore=docstore,\n",
    "    index_to_docstore_id=index_to_docstore_id\n",
    ")\n",
    "\n",
    "# 4. LangChain í˜¸í™˜ êµ¬ì¡°ë¡œ ì €ì¥\n",
    "db.save_local(\"solo_leveling_faiss_langchain\")\n",
    "print(\"ë³€í™˜ ì™„ë£Œ: solo_leveling_faiss_langchain í´ë” ìƒì„±ë¨\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc27fe9f-c69a-4dab-8d9f-603c7079cad6",
   "metadata": {},
   "source": [
    "## 1. tsv full data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60146aa5-f97a-4931-a4f2-7f8d33136f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ì—í”¼ì†Œë“œ                     scene_text  type\n",
      "0  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „    ë„¤, ê¹€ìƒì‹ ì•„ì €ì”¨. ì‹ ê²½ ì¨ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.    ëŒ€ì‚¬\n",
      "1  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „               ë‚´ ì´ë¦„ì€ ì„±ì§„ìš°. Eê¸‰ í—Œí„°  ë‚´ì ì„¤ëª…\n",
      "2  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „         ë­˜ìš” í•˜í•˜... ì˜¤ëŠ˜ë„ ì˜ ë¶€íƒë“œë¦´ê²Œìš”.    ëŒ€ì‚¬\n",
      "3  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „    í—Œí„°í˜‘íšŒ ì†Œì† ì¤‘ ê°€ì¥ ë‚®ì€ ê³„ê¸‰, ìµœì•½ì˜ í—Œí„°.  ë‚´ì ì„¤ëª…\n",
      "4  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „  ì–´? ì•ˆë…•í•˜ì„¸ìš”. ì£¼í¬ ì”¨ë„ ì´ë²ˆ ë ˆì´ë“œ ê°€ì‹œëŠ”êµ°ìš”.    ëŒ€ì‚¬\n",
      "ì „ì²´ ë¬¸ì¥ ìˆ˜: 549\n",
      "ì»¬ëŸ¼ ëª©ë¡: ['ì—í”¼ì†Œë“œ', 'scene_text', 'type']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"sl_webtoon_full_data_sequential.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "print(\"ì „ì²´ ë¬¸ì¥ ìˆ˜:\", len(df))\n",
    "print(\"ì»¬ëŸ¼ ëª©ë¡:\", df.columns.tolist())\n",
    "\n",
    "# 549\n",
    "#ì»¬ëŸ¼ ëª©ë¡: ['ì—í”¼ì†Œë“œ', 'scene_text', 'type']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd35b473-3d92-4d9d-a8ee-5565dff05e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ì—í”¼ì†Œë“œ                   scene_text  type\n",
      "0  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „  ë„¤, ê¹€ìƒì‹ ì•„ì €ì”¨. ì‹ ê²½ ì¨ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.    ëŒ€ì‚¬\n",
      "1  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „             ë‚´ ì´ë¦„ì€ ì„±ì§„ìš°. Eê¸‰ í—Œí„°  ë‚´ì ì„¤ëª…\n",
      "2  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „       ë­˜ìš” í•˜í•˜... ì˜¤ëŠ˜ë„ ì˜ ë¶€íƒë“œë¦´ê²Œìš”.    ëŒ€ì‚¬\n",
      "ì»¬ëŸ¼: ['ì—í”¼ì†Œë“œ', 'scene_text', 'type'] ì „ì²´ í–‰: 549\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"sl_webtoon_full_data_sequential.tsv\", sep=\"\\t\")\n",
    "print(df.head(3))\n",
    "print(\"ì»¬ëŸ¼:\", df.columns.tolist(), \"ì „ì²´ í–‰:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa5db259-991a-48b1-859f-2308432737c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #0 ëŒ€ì‚¬ ë„¤, ê¹€ìƒì‹ ì•„ì €ì”¨. ì‹ ê²½ ì¨ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.', '[1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #1 ë‚´ì ì„¤ëª… ë‚´ ì´ë¦„ì€ ì„±ì§„ìš°. Eê¸‰ í—Œí„°', '[1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #2 ëŒ€ì‚¬ ë­˜ìš” í•˜í•˜... ì˜¤ëŠ˜ë„ ì˜ ë¶€íƒë“œë¦´ê²Œìš”.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df['row_id'] = df.index #ì¸ë±ìŠ¤ ì»¬ëŸ¼ ì¶”ê°€ <- ì›ë³¸ ì¶”ì ìš©\n",
    "\n",
    "df['text'] = df.apply(\n",
    "    lambda x: f\"[{x['ì—í”¼ì†Œë“œ']}] #{x['row_id']} {x['type']} {x['scene_text']}\", #rag ë¬¸ì¥ ì»¬ëŸ¼ ìƒì„±\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(df['text'].head(3).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b95c977-5485-4fdf-b5d8-fb837a0a8cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìµœì¢… ë¬¸ì¥ ìˆ˜: 549\n"
     ]
    }
   ],
   "source": [
    "texts = df['text'].tolist()\n",
    "print(\"ìµœì¢… ë¬¸ì¥ ìˆ˜:\", len(texts))\n",
    "# 549"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be84111-8a20-49b4-827a-305e9498fe15",
   "metadata": {},
   "source": [
    "## 2. Rag ë¬¸ì¥ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f948651-c16f-40d6-9b96-2aaafb1d7bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ˆì‹œ 5ê°œ:\n",
      "- [1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #0 ëŒ€ì‚¬ ë„¤, ê¹€ìƒì‹ ì•„ì €ì”¨. ì‹ ê²½ ì¨ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.\n",
      "- [1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #1 ë‚´ì ì„¤ëª… ë‚´ ì´ë¦„ì€ ì„±ì§„ìš°. Eê¸‰ í—Œí„°\n",
      "- [1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #2 ëŒ€ì‚¬ ë­˜ìš” í•˜í•˜... ì˜¤ëŠ˜ë„ ì˜ ë¶€íƒë“œë¦´ê²Œìš”.\n",
      "- [1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #3 ë‚´ì ì„¤ëª… í—Œí„°í˜‘íšŒ ì†Œì† ì¤‘ ê°€ì¥ ë‚®ì€ ê³„ê¸‰, ìµœì•½ì˜ í—Œí„°.\n",
      "- [1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #4 ëŒ€ì‚¬ ì–´? ì•ˆë…•í•˜ì„¸ìš”. ì£¼í¬ ì”¨ë„ ì´ë²ˆ ë ˆì´ë“œ ê°€ì‹œëŠ”êµ°ìš”.\n",
      "\n",
      "ìµœì¢… ë¬¸ì¥ ìˆ˜: 549\n"
     ]
    }
   ],
   "source": [
    "# 2ë‹¨ê³„: ìµœì¢… RAG ë¬¸ì¥ ìƒì„±\n",
    "df['row_id'] = df.index  # ì›ë³¸ ì¶”ì ìš© ì¸ë±ìŠ¤\n",
    "df['text'] = df.apply(\n",
    "    lambda x: f\"[{x['ì—í”¼ì†Œë“œ']}] #{x['row_id']} {x['type']} {x['scene_text']}\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"ì˜ˆì‹œ 5ê°œ:\")\n",
    "for t in df['text'].head(5).tolist():\n",
    "    print(\"-\", t)\n",
    "\n",
    "texts = df['text'].tolist()\n",
    "print(\"\\nìµœì¢… ë¬¸ì¥ ìˆ˜:\", len(texts))\n",
    "#549"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d659a2e-2c7b-4158-b676-d85abc5d3e92",
   "metadata": {},
   "source": [
    "## 3. í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ, ë²¡í„° db - solo_leveling_faiss_ko\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ef1ac89-0931-48a8-9024-26150004b81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ë²¡í„°DB ìƒì„± ì™„ë£Œ. ì´ ë¬¸ì¥ ìˆ˜: 549\n",
      " 'solo_leveling_faiss_ko' í´ë”ì— ì €ì¥\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name='jhgan/ko-sroberta-multitask')\n",
    "\n",
    "db = FAISS.from_texts(texts, embedding_model)\n",
    "print(\" ë²¡í„°DB ìƒì„± ì™„ë£Œ. ì´ ë¬¸ì¥ ìˆ˜:\", len(texts))\n",
    "\n",
    "db.save_local(\"solo_leveling_faiss_ko\")\n",
    "print(\" 'solo_leveling_faiss_ko' í´ë”ì— ì €ì¥\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6acad70-ae02-4808-800e-fee4c2a36153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] [2ê¶Œ_3í™”_í€˜ìŠ¤íŠ¸ ] #332 ëŒ€ì‚¬ ë˜ì „ì— ì‚¬ëŠ” ë§ˆìˆ˜ë¼ë©´ ë§ˆì •ì„ì„ ê°–ê³  ìˆì„ ì¤„ ì•Œì•˜ëŠ”ë°...ì™„ì „íˆ ë‹¤ë¥¸ ë¶€ë¥˜ì¸ê°€.\n",
      "[2] [1ê¶Œ_3í™”_í€˜ìŠ¤íŠ¸] #132 ëŒ€ì‚¬ ì—¬... ì—¬ê¸´?!  ì‚¬ë§‰...!!\n",
      "[3] [2ê¶Œ_3í™”_í€˜ìŠ¤íŠ¸ ] #331 ëŒ€ì‚¬ ì´ ë…€ì„ë“¤ì€ ë§ˆì •ì„ ê°™ì€ ê±´ ì•ˆ ì£¼ë‚˜?\n",
      "[4] [2ê¶Œ_4í™”_ë³´ìŠ¤ì „] #457 ë‚´ì ì„¤ëª… ê²½í—˜ì´ ë§ìœ¼ë©´ ë§ì„ìˆ˜ë¡ ë­í¬ê°€ ë†’ìœ¼ë©´ ë†’ì„ìˆ˜ë¡ ë§ˆìˆ˜ë“¤ì—ê²Œì„œ ë‚˜ì˜¤ëŠ” ë§ˆì •ì„ì€ ê°€ì¹˜ë¥¼ ë”í•´ ê°„ë‹¤.\n",
      "[5] [2ê¶Œ_4í™”_ë³´ìŠ¤ì „] #449 ëŒ€ì‚¬ ë¬¸ì œëŠ” ì§€ëŠ¥ì¸ë°... ë§ˆë²•ê³¼ ê´€ë ¨ëœ ìŠ¤íƒ¯ì¼ ê²ƒ ê°™ê¸´ í•œë°, ì´ê²Œ í”¼ë£¡í• ê¹Œ?\n"
     ]
    }
   ],
   "source": [
    "db = FAISS.load_local(\"solo_leveling_faiss_ko\", embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "\n",
    "query = \"ë§ˆë‚˜ì„ì´ ë­ì§€?\"\n",
    "docs = db.similarity_search(query, k=5)\n",
    "\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"[{i}] {doc.page_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b215211a-ed27-4571-a9cf-b5792c6fa20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## rag í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "caf4de14-02ef-4143-97eb-00cdab7a2fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"kakaocorp/kanana-nano-2.1b-instruct\",\n",
    "    device=0  \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ef2966e-c110-4565-8ddf-1a1bee864934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "/tmp/ipykernel_1304235/3834059051.py:17: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
      "/tmp/ipykernel_1304235/3834059051.py:35: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹µë³€: ë‹¤ìŒ ë¬¸ë§¥ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.\n",
      "\n",
      "ë¬¸ë§¥:\n",
      "[1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #1 ë‚´ì ì„¤ëª… ë‚´ ì´ë¦„ì€ ì„±ì§„ìš°. Eê¸‰ í—Œí„°\n",
      "\n",
      "[2ê¶Œ_4í™”_ë³´ìŠ¤ì „] #451 ëŒ€ì‚¬ í—Œí„° ì„±ì§„ìš°ì…ë‹ˆë‹¤.\n",
      "\n",
      "[1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #9 ë‚´ì ì„¤ëª… Eê¸‰ í—Œí„° ì„±ì§„ìš°.\n",
      "\n",
      "[3ê¶Œ_7í™”_ì´ìƒí•œë ˆì´ë“œ] #484 ë‚´ì ì„¤ëª… ê·¸ ë…€ì„ì´ ì›í•˜ëŠ” ê±´ ì‹¤ë ¥ì€ ìˆì§€ë§Œ ë“±ê¸‰ì´ ë‚®ì€ í—Œí„°ë‹ˆê¹Œ.\n",
      "\n",
      "[2ê¶Œ_4í™”_ë³´ìŠ¤ì „] #468 ë‚´ì ì„¤ëª… ëŠ¥ë ¥ì¹˜ë¥¼ ì˜¬ë¦´ ìˆ˜ ìˆëŠ” í—Œí„°ê°€ ìˆë‹¤?\n",
      "\n",
      "ì§ˆë¬¸:\n",
      "ì„±ì§„ìš°ëŠ” ëª‡ ê¸‰ í—Œí„°ì§€?\n",
      "\n",
      "ë‹µë³€: ì„±ì§„ìš°ëŠ” Eê¸‰ í—Œí„°ì…ë‹ˆë‹¤.  #1 ë‚´ì ì„¤ëª… ë° #9 ë‚´ì ì„¤ëª… ì°¸ê³ .  #450 ë‚´ì ì„¤ëª… ë° #468 ë‚´ì ì„¤ëª…ì—ì„œë„ ì´ ì •ë³´ê°€ í™•ì¸ë©ë‹ˆë‹¤.  Eê¸‰ í—Œí„°ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.  #4í™”_ë³´ìŠ¤ì „_ì„±ì§„ìš°_ëŒ€ì‚¬ì—ì„œë„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  ì„±ì§„ìš°ëŠ” Eê¸‰ í—Œí„°ì…ë‹ˆë‹¤.  ê¸‰ì€ Eê¸‰ì…ë‹ˆë‹¤.  í—Œí„° ë“±ê¸‰ì€ Eê¸‰ì…ë‹ˆë‹¤.  Eê¸‰ í—Œí„° ì„±ì§„ìš°.  #1 ë‚´ì ì„¤ëª… ë° #9 ë‚´ì ì„¤ëª…ì— ëª…ì‹œë˜ì–´ ìˆìŠµë‹ˆë‹¤.  Eê¸‰ í—Œí„°ê°€ ë§ìŠµë‹ˆë‹¤.  í—Œí„° ë“±ê¸‰ì€ Eê¸‰ì…ë‹ˆë‹¤.  ì„±ì§„ìš°ì˜ í—Œí„° ë“±ê¸‰ì€ Eê¸‰ì…ë‹ˆë‹¤.  Eê¸‰ í—Œí„° ì„±ì§„ìš°ì…ë‹ˆë‹¤.  Eê¸‰ í—Œí„°ê°€ ë§ìŠµë‹ˆë‹¤.  ì„±ì§„ìš°ëŠ” Eê¸‰ í—Œí„°ì…ë‹ˆë‹¤.  í—Œí„° ë“±ê¸‰ì€ Eê¸‰ì…ë‹ˆë‹¤.  ì„±ì§„ìš°ì˜ í—Œí„° ë“±ê¸‰ì€ Eê¸‰ì…ë‹ˆë‹¤.  Eê¸‰ í—Œí„° ì„±ì§„ìš°.  #4í™”_ë³´ìŠ¤ì „_ì„±ì§„\n",
      "\n",
      "ì°¸ì¡° ë¬¸ì„œ:\n",
      "[1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #1 ë‚´ì ì„¤ëª… ë‚´ ì´ë¦„ì€ ì„±ì§„ìš°. Eê¸‰ í—Œí„°\n",
      "[2ê¶Œ_4í™”_ë³´ìŠ¤ì „] #451 ëŒ€ì‚¬ í—Œí„° ì„±ì§„ìš°ì…ë‹ˆë‹¤.\n",
      "[1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #9 ë‚´ì ì„¤ëª… Eê¸‰ í—Œí„° ì„±ì§„ìš°.\n",
      "[3ê¶Œ_7í™”_ì´ìƒí•œë ˆì´ë“œ] #484 ë‚´ì ì„¤ëª… ê·¸ ë…€ì„ì´ ì›í•˜ëŠ” ê±´ ì‹¤ë ¥ì€ ìˆì§€ë§Œ ë“±ê¸‰ì´ ë‚®ì€ í—Œí„°ë‹ˆê¹Œ.\n",
      "[2ê¶Œ_4í™”_ë³´ìŠ¤ì „] #468 ë‚´ì ì„¤ëª… ëŠ¥ë ¥ì¹˜ë¥¼ ì˜¬ë¦´ ìˆ˜ ìˆëŠ” í—Œí„°ê°€ ìˆë‹¤?\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name='jhgan/ko-sroberta-multitask')\n",
    "vectorstore = FAISS.load_local(\"solo_leveling_faiss_ko\", embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "model_name = \"kakaocorp/kanana-nano-2.1b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16).to(\"cuda\")\n",
    "\n",
    "llm_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=256)\n",
    "llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
    "\n",
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"ë‹¤ìŒ ë¬¸ë§¥ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.\\n\\në¬¸ë§¥:\\n{context}\\n\\nì§ˆë¬¸:\\n{question}\\n\\në‹µë³€:\"\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 5}),\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": custom_prompt  }\n",
    ")\n",
    "\n",
    "#ì§ˆë¬¸\n",
    "query = \"ì„±ì§„ìš°ëŠ” ëª‡ ê¸‰ í—Œí„°ì§€?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(\"ë‹µë³€:\", result[\"result\"])\n",
    "print(\"\\nì°¸ì¡° ë¬¸ì„œ:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(doc.page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10cc72f-d587-4dc3-a6a4-e56b08d0a985",
   "metadata": {},
   "source": [
    "## 4. í™©ë™ì„ ì—í”¼ì†Œë“œ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46946824-27c5-4a95-a293-d6b3ab905277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì„ íƒì§€]\n",
      "1. 1-1. í™©ë™ì„ ë¬´ë¦¬ë¥¼ ëª¨ë‘ ì²˜ì¹˜í•œë‹¤.\n",
      "2. 1-2. í™©ë™ì„ ë¬´ë¦¬ì™€ ì§„í˜¸ë¥¼ í¬í•¨í•˜ì—¬ ëª¨ë‘ ì²˜ì¹˜í•œë‹¤.\n",
      "3. 2. í™©ë™ì„ ë¬´ë¦¬ë¥¼ ê¸°ì ˆì‹œí‚¤ê³  ì‚´ë ¤ë‘”ë‹¤.\n",
      "4. 3-1. ë§ˆì •ì„ì„ ë“¤ê³  ë„ë§ì¹œë‹¤.\n",
      "5. 3-2. ì‹œìŠ¤í…œì„ ê±°ë¶€í•˜ê³  ê·¸ëƒ¥ ë„ë§ì¹œë‹¤.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ì„ íƒ ë²ˆí˜¸ ì…ë ¥:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì‚¬ìš©ì ì„ íƒ]: 3-2. ì‹œìŠ¤í…œì„ ê±°ë¶€í•˜ê³  ê·¸ëƒ¥ ë„ë§ì¹œë‹¤.\n",
      "\n",
      "[ê²€ìƒ‰ëœ ê·¼ê±° ë¬¸ì„œ ì˜ˆì‹œ]\n",
      "[1ê¶Œ_3í™”_í€˜ìŠ¤íŠ¸] #162 ëŒ€ì‚¬ ë„ë§ì¹˜ëŠ” ê±´ ìì‹  ìˆìœ¼ë‹ˆê¹Œ, ë§Œì•½ ì§€ë‚œë²ˆì²˜ëŸ¼ ìœ„í—˜í•´ì§€ë©´ ë¬¼ë¶ˆ ê°€ë¦¬ì§€ ë§ê³  ë„ë§ì¹˜ì!\n",
      "[1ê¶Œ_3í™”_í€˜ìŠ¤íŠ¸] #167 ëŒ€ì‚¬ ì–´ì©Œì§€... ì—¬ì°¨í•˜ë©´ ë„ë§ì¹˜ë ¤ê³  í–ˆëŠ”ë° í‡´ë¡œë¥¼ ì°¨ë‹¨í•˜ë©´ ë„ë§ì¹  ìˆ˜ê°€ ì—†ì–ì•„!\n",
      "[2ê¶Œ_2í™”_ì„¸ê°€ì§€ê·œìœ¨] #227 ë‚´ì ì„¤ëª… ìš°ë¦¬ê°€ ì‹¤íŒ¨í•˜ë©´... ì €ê²Œ ë°–ìœ¼ë¡œ ë‚˜ê°ˆ ìˆ˜ë„ ìˆë‹¤ëŠ” ë§ì¸ê°€.\n",
      "[2ê¶Œ_2í™”_ì„¸ê°€ì§€ê·œìœ¨] #275 ì‹œìŠ¤í…œ ìˆ˜ë½ì„ ê±°ë¶€í•˜ì‹¤ ê²½ìš°, 0.02ì´ˆ í›„ ê·€í•˜ì˜ ì‹¬ì¥ì´ ì •ì§€í•©ë‹ˆë‹¤.\n",
      "[2ê¶Œ_2í™”_ì„¸ê°€ì§€ê·œìœ¨] #192 ë‚´ì ì„¤ëª… ê°€ê¹Œì´ ê°ˆ ìˆ˜ë„ ì—†ê³  ë„ë§ë„ ëª» ì³! ...\n",
      "\n",
      "[ì„±ì§„ìš° ì‘ë‹µ]\n",
      "ë„ë§ì¹˜ëŠ” ê²Œ ë” ë‚˜ì„ ê²ƒ ê°™ì•„. í•˜ì§€ë§Œ ì•ˆì „í•˜ê²Œ ë„ë§ì¹  ìˆ˜ ìˆì„ì§€ ê±±ì •ì´ì•¼. ì–´ì¨Œë“  ì¼ë‹¨ ë„ë§ì³ë³´ì. ëŒ€ì‹  ë‹¤ì‹œëŠ” ì´ëŸ° ìƒí™©ì´ ì˜¤ì§€ ì•Šë„ë¡ ì¡°ì‹¬í•´ì•¼ê² ì–´. ë„ë§ì¹˜ê¸° ì „ì— ì ì‹œ ìˆ¨ì„ ê³ ë¥´ì. ì¤€ë¹„ê°€ ë˜ë©´ ë¹ ë¥´ê²Œ ì›€ì§ì´ì. ë„ë§ì¹  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì°¾ì•„ë³´ì. ë„ë§ì¹˜ë‹¤ ë³´ë©´ ë” ë‚˜ì€ ë°©ë²•ë„ ì°¾ì„ ìˆ˜ ìˆì„ ê±°ì•¼. ë„ë§ì¹˜ëŠ” ê²Œ ìµœì„ ì˜ ì„ íƒì´ì•¼. í•˜ì§€ë§Œ í•­ìƒ ì¡°ì‹¬í•˜ê³  ëŒ€ë¹„í•´ì•¼ í•´. ë„ë§ì¹˜ëŠ” ë™ì•ˆì—ë„ ìƒí™©ì„ ì˜ íŒŒì•…í•˜ê³  ìˆì–´ì•¼ í•´. ë„ë§ì¹˜ë©´ì„œ ë” ë‚˜ì€ ì „ëµì„ ì„¸ìš¸ ìˆ˜ ìˆì„ì§€ë„ ëª°ë¼. ë„ë§ì¹˜ëŠ” ê²Œ ë‘ë ¤ì›Œì§€ë©´ ë” í° ìœ„í—˜ì´ ì˜¬ ìˆ˜ë„ ìˆìœ¼ë‹ˆê¹Œ, ì¼ë‹¨ ë„ë§ì¹˜ëŠ” ê²Œ ë§ëŠ” ê²ƒ ê°™ì•„. í•˜ì§€ë§Œ ë„ë§ì¹œ í›„ì— ë” ë‚˜ì€\n"
     ]
    }
   ],
   "source": [
    "choices = [\n",
    "    \"1-1. í™©ë™ì„ ë¬´ë¦¬ë¥¼ ëª¨ë‘ ì²˜ì¹˜í•œë‹¤.\",\n",
    "    \"1-2. í™©ë™ì„ ë¬´ë¦¬ì™€ ì§„í˜¸ë¥¼ í¬í•¨í•˜ì—¬ ëª¨ë‘ ì²˜ì¹˜í•œë‹¤.\",\n",
    "    \"2. í™©ë™ì„ ë¬´ë¦¬ë¥¼ ê¸°ì ˆì‹œí‚¤ê³  ì‚´ë ¤ë‘”ë‹¤.\",\n",
    "    \"3. ì‹œìŠ¤í…œì„ ê±°ë¶€í•˜ê³  ê·¸ëƒ¥ ë„ë§ì¹œë‹¤.\"\n",
    "]\n",
    "\n",
    "print(\"\\n[ì„ íƒì§€]\")\n",
    "for idx, choice in enumerate(choices, start=1):\n",
    "    print(f\"{idx}. {choice}\")\n",
    "\n",
    "user_idx = int(input(\"\\nì„ íƒ ë²ˆí˜¸ ì…ë ¥: \")) - 1\n",
    "user_choice = choices[user_idx]\n",
    "print(f\"\\n[ì‚¬ìš©ì ì„ íƒ]: {user_choice}\")\n",
    "\n",
    "result = qa_chain({\"query\": user_choice})\n",
    "\n",
    "retrieved_context = \"\\n\".join([doc.page_content for doc in result[\"source_documents\"]])\n",
    "print(\"\\n[ê²€ìƒ‰ëœ ê·¼ê±° ë¬¸ì„œ ì˜ˆì‹œ]\")\n",
    "print(retrieved_context[:600], \"...\") \n",
    "\n",
    "# 4. ì„±ì§„ìš° ë§íˆ¬ ëŒ€ì‚¬ ìƒì„±\n",
    "prompt = f\"\"\"\n",
    "ë‹¹ì‹ ì€ ì›¹íˆ° 'ë‚˜ í˜¼ìë§Œ ë ˆë²¨ì—…'ì˜ ì„±ì§„ìš°ì…ë‹ˆë‹¤.\n",
    "í˜„ì¬ ìƒí™©:\n",
    "{retrieved_context}\n",
    "\n",
    "ì‚¬ìš©ì ì„ íƒ: {user_choice}\n",
    "\n",
    "ì„±ì§„ìš°ì˜ ë§íˆ¬ë¡œ ê°„ê²°í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€ì‚¬ë¥¼ 1~2ë¬¸ì¥ ìƒì„±í•˜ì„¸ìš”.\n",
    "ì¤‘ë³µëœ ë‚´ìš©ì´ë‚˜ ë¹„ìŠ·í•œ ë¬¸ì¥ì€ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.\n",
    "\"\"\"\n",
    "\n",
    "response = generator(prompt, \n",
    "                     max_new_tokens=200, \n",
    "                     do_sample=True, \n",
    "                     temperature=0.6,\n",
    "                     top_p = 0.9,\n",
    "                     return_full_text=False  # ì¶”ê°€\n",
    ")[0][\"generated_text\"]\n",
    "print(\"\\n[ì„±ì§„ìš° ì‘ë‹µ]\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b183dc5-56be-4464-b737-00f11b30bbd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "495143f6-df63-496d-a35c-4fff9f40f6b5",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ka)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
