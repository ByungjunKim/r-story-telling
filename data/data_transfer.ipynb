{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd989e2e-79b5-4a3b-bc2f-21e366baeb73",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Full_Data -> sequntial ë³€í™˜\n",
    "- full_data: (ì›¹íˆ°ì±…1ê¶Œ~4ê¶Œê¹Œì§€ == ì• ë‹ˆë©”ì´ì…˜ ê¸°ì¤€ 1ê¸°) - íŠ¹ì • ì—í”¼ì†Œë“œ 3ê°œ ì œì™¸í•œ ê²ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c09c0d9c-77b1-4640-9ce7-43d97b16f0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë³€í™˜, ì €ì¥ ìœ„ì¹˜: sl_webtoon_full_data_sequential.tsv\n",
      "         ì—í”¼ì†Œë“œ                     scene_text  type\n",
      "0  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „    ë„¤, ê¹€ìƒì‹ ì•„ì €ì”¨. ì‹ ê²½ ì¨ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.    ëŒ€ì‚¬\n",
      "1  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „               ë‚´ ì´ë¦„ì€ ì„±ì§„ìš°. Eê¸‰ í—Œí„°  ë‚´ì ì„¤ëª…\n",
      "2  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „         ë­˜ìš” í•˜í•˜... ì˜¤ëŠ˜ë„ ì˜ ë¶€íƒë“œë¦´ê²Œìš”.    ëŒ€ì‚¬\n",
      "3  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „    í—Œí„°í˜‘íšŒ ì†Œì† ì¤‘ ê°€ì¥ ë‚®ì€ ê³„ê¸‰, ìµœì•½ì˜ í—Œí„°.  ë‚´ì ì„¤ëª…\n",
      "4  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „  ì–´? ì•ˆë…•í•˜ì„¸ìš”. ì£¼í¬ ì”¨ë„ ì´ë²ˆ ë ˆì´ë“œ ê°€ì‹œëŠ”êµ°ìš”.    ëŒ€ì‚¬\n",
      "5  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „   ë‚˜ì—ê²Œ ì´ëŸ° ì¼ì´ ì¼ì–´ë‚  ì¤„ì€...ìƒìƒë„ ëª» í–ˆë‹¤.  ë‚´ì ì„¤ëª…\n",
      "6  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „            ì–´ì©Œë‹¤ë³´ë‹ˆ ê·¸ë ‡ê²Œ ëë„¤ìš” í•˜í•˜...    ëŒ€ì‚¬\n",
      "7  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „                        ëŒ€í•œë¯¼êµ­ ì„œìš¸  ë‚´ì ì„¤ëª…\n",
      "8  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „         Eê¸‰ ë˜ì „ì´ì—ˆëŠ”ë° ì €ë§Œ ë‹¤ì³ì„œ ë‚˜ì™”ì–´ìš”.    ëŒ€ì‚¬\n",
      "9  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „                     Eê¸‰ í—Œí„° ì„±ì§„ìš°.  ë‚´ì ì„¤ëª…\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_path = \"sl_webtoon_full_data.tsv\"\n",
    "output_path = \"sl_webtoon_full_data_sequential.tsv\"\n",
    "\n",
    "df = pd.read_csv(input_path, sep='\\t', encoding='utf-8')\n",
    "\n",
    "df = df.fillna(\"\") #ê²°ì¸¡ì¹˜ \"\" ë¡œ ë³€í™˜\n",
    "\n",
    "cols = ['ì—í”¼ì†Œë“œëª…', 'ëŒ€ì‚¬', 'ë‚´ì ì„¤ëª…', 'ì‹œìŠ¤í…œ']\n",
    "\n",
    "rows = []\n",
    "for ep, group in df.groupby('ì—í”¼ì†Œë“œëª…'):\n",
    "    for idx, row in group.iterrows():\n",
    "        for col in ['ëŒ€ì‚¬', 'ë‚´ì ì„¤ëª…', 'ì‹œìŠ¤í…œ']:\n",
    "            text = row[col].strip()\n",
    "            if text:  \n",
    "                rows.append({\n",
    "                    'ì—í”¼ì†Œë“œ': ep,\n",
    "                    'scene_text': text,\n",
    "                    'type': col  \n",
    "                })\n",
    "\n",
    "seq_df = pd.DataFrame(rows)\n",
    "\n",
    "seq_df.to_csv(output_path, sep='\\t', index=False, encoding='utf-8')\n",
    "\n",
    "print(\"ë³€í™˜, ì €ì¥ ìœ„ì¹˜:\", output_path)\n",
    "print(seq_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26b8107-952b-43b9-872b-e62d32fd1e8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ë¡œ ì„ë² ë”© ìƒì„± + faiss ì¸ë±ìŠ¤+ Rag db êµ¬ì¶•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4a30fca-d526-4902-91a6-d1ec4c8004b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG DB êµ¬ì¶• ì™„ë£Œ, ë¬¸ì¥ ìˆ˜: 549\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "data_path = \"sl_webtoon_full_data_sequential.tsv\"\n",
    "\n",
    "df = pd.read_csv(data_path, sep=\"\\t\")\n",
    "df[\"text\"] = df[[\"ì—í”¼ì†Œë“œ\", \"scene_text\", \"type\"]].fillna(\"\").agg(\" \".join, axis=1)\n",
    "\n",
    "model = SentenceTransformer('jhgan/ko-sroberta-multitask') #í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ \n",
    "\n",
    "embeddings = model.encode(df[\"text\"].tolist(), convert_to_numpy=True)\n",
    "\n",
    "dim = embeddings.shape[1]  # ëª¨ë¸ ì¶œë ¥ ì°¨ì› ìë™ í™•ì¸\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(embeddings)\n",
    "\n",
    "faiss.write_index(index, \"solo_leveling_faiss_ko.index\")\n",
    "with open(\"solo_leveling_texts.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df[\"text\"].tolist(), f)\n",
    "\n",
    "print(\"RAG DB êµ¬ì¶• ì™„ë£Œ, ë¬¸ì¥ ìˆ˜:\", len(df))\n",
    "#ë¬¸ì¥ ìˆ˜ : 549\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ffc416-24d7-4a0e-a046-b30e317a78a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. index, pickle í™•ì¸ ì„ë² ë”© ê²€ìƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484907bd-15ea-4536-8f85-71104ef1ac9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7f841c6-ba70-45ee-970e-98199090275e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìœ ì‚¬ ì¥ë©´ Top 10 \n",
      "\n",
      "[ì ìˆ˜: 83.3571] 1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „ ë‚´ ì´ë¦„ì€ ì„±ì§„ìš°. Eê¸‰ í—Œí„° ë‚´ì ì„¤ëª…\n",
      "[ì ìˆ˜: 88.2755] 2ê¶Œ_4í™”_ë³´ìŠ¤ì „ í—Œí„° ì„±ì§„ìš°ì…ë‹ˆë‹¤. ëŒ€ì‚¬\n",
      "[ì ìˆ˜: 93.2208] 1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „ Eê¸‰ í—Œí„° ì„±ì§„ìš°. ë‚´ì ì„¤ëª…\n",
      "[ì ìˆ˜: 99.7465] 3ê¶Œ_7í™”_ì´ìƒí•œë ˆì´ë“œ ê·¸ ë…€ì„ì´ ì›í•˜ëŠ” ê±´ ì‹¤ë ¥ì€ ìˆì§€ë§Œ ë“±ê¸‰ì´ ë‚®ì€ í—Œí„°ë‹ˆê¹Œ. ë‚´ì ì„¤ëª…\n",
      "[ì ìˆ˜: 102.8061] 3ê¶Œ_7í™”_ì´ìƒí•œë ˆì´ë“œ Sê¸‰ í—Œí„°ì¸ í™©ë™ìˆ˜ë¥¼ ë§í•˜ëŠ” ê²ë‹ˆê¹Œ? ëŒ€ì‚¬\n",
      "[ì ìˆ˜: 109.0561] 2ê¶Œ_4í™”_ë³´ìŠ¤ì „ ëŠ¥ë ¥ì¹˜ë¥¼ ì˜¬ë¦´ ìˆ˜ ìˆëŠ” í—Œí„°ê°€ ìˆë‹¤? ë‚´ì ì„¤ëª…\n",
      "[ì ìˆ˜: 109.9106] 1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „ í—Œí„°í˜‘íšŒ ì†Œì† ì¤‘ ê°€ì¥ ë‚®ì€ ê³„ê¸‰, ìµœì•½ì˜ í—Œí„°. ë‚´ì ì„¤ëª…\n",
      "[ì ìˆ˜: 110.5650] 2ê¶Œ_2í™”_ì„¸ê°€ì§€ê·œìœ¨ ì—¬ê¸°ì„œ ê¸°ë‹¤ë¦¬ê³  ìˆìœ¼ë©´ ë‹¤ë¥¸ í—Œí„°ë“¤ì´ êµ¬ì¡°í•˜ëŸ¬ ì˜¬ê¹Œìš”? ëŒ€ì‚¬\n",
      "[ì ìˆ˜: 114.7391] 1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „ ëª©ìˆ¨ì„ ê±°ëŠ” ìœ„í—˜í•œ ì§ì—… 'í—Œí„°'. ë‚˜ë¼ê³  ì¢‹ì•„ì„œ ì´ ì¼ì„ í•˜ëŠ” ê±´ ì•„ë‹ˆë‹¤. ë‚´ì ì„¤ëª…\n",
      "[ì ìˆ˜: 119.2824] 1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „ ê³ ì¡¸ ì¶œì‹ ì— ë”±íˆ ì˜í•˜ëŠ” ê²ƒë„ ì—†ëŠ” ë‚´ê²Œ, í—Œí„°ë¼ëŠ” ì§ì—…ì€ í”¼í•  ìˆ˜ ì—†ëŠ” ì„ íƒì´ì—ˆë‹¤. ë‚´ì ì„¤ëª…\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "index = faiss.read_index(\"solo_leveling_faiss_ko.index\")\n",
    "with open(\"solo_leveling_texts.pkl\", \"rb\") as f:\n",
    "    texts = pickle.load(f)\n",
    "\n",
    "model = SentenceTransformer('jhgan/ko-sroberta-multitask')\n",
    "\n",
    "query = \"ì„±ì§„ìš°ëŠ” ëª‡ ê¸‰ í—Œí„°?\"\n",
    "\n",
    "query_vec = model.encode([query])\n",
    "D, I = index.search(query_vec, k=10)  # ìƒìœ„ 5ê°œ\n",
    "\n",
    "print(\"ìœ ì‚¬ ì¥ë©´ Top 10 \\n\")\n",
    "for idx, score in zip(I[0], D[0]):\n",
    "    print(f\"[ì ìˆ˜: {score:.4f}] {texts[idx]}\")\n",
    "#ì ìˆ˜ ë‚®ì„ ìˆ˜ë¡ ìœ ì‚¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a758d87-767b-43d6-b9fe-957b405d6f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] [1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #1 ë‚´ì ì„¤ëª… ë‚´ ì´ë¦„ì€ ì„±ì§„ìš°. Eê¸‰ í—Œí„°\n",
      "[2] [3ê¶Œ_7í™”_ì´ìƒí•œë ˆì´ë“œ] #487 ëŒ€ì‚¬ Sê¸‰ í—Œí„°ì¸ í™©ë™ìˆ˜ë¥¼ ë§í•˜ëŠ” ê²ë‹ˆê¹Œ?\n",
      "[3] [1ê¶Œ_3í™”_í€˜ìŠ¤íŠ¸] #91 ëŒ€ì‚¬ ì£¼í¬ ì”¨ë‚˜ ì†¡ì¹˜ì—´ ì•„ì €ì”¨ëŠ” ì–´ë–»ê²Œ ë˜ì…¨ì£ ?\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The de-serialization relies loading a pickle file. Pickle files can be modified to deliver a malicious payload that results in execution of arbitrary code on your machine.You will need to set `allow_dangerous_deserialization` to `True` to enable deserialization. If you do this, make sure that you trust the source of the data. For example, if you are loading a file that you created, and know that no one else has modified the file, then this is safe to do. Do not set this to `True` if you are loading a file from an untrusted source (e.g., some random site on the internet.).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# 1. ë²¡í„° DB ë¡œë“œ\u001b[39;00m\n\u001b[1;32m     21\u001b[0m embedding \u001b[38;5;241m=\u001b[39m HuggingFaceEmbeddings(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjhgan/ko-sroberta-multitask\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_local\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msolo_leveling_faiss_ko\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 2. ì˜ˆì‹œ ì§ˆì˜\u001b[39;00m\n\u001b[1;32m     25\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mì„±ì§„ìš°ëŠ” í™©ë™ì„ê³¼ ì²˜ìŒ ë§Œë‚œ ì¥ë©´ì—ì„œ ë¬´ì—‡ì„ í–ˆì–´?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_community/vectorstores/faiss.py:1190\u001b[0m, in \u001b[0;36mFAISS.load_local\u001b[0;34m(cls, folder_path, embeddings, index_name, allow_dangerous_deserialization, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load FAISS index, docstore, and index_to_docstore_id from disk.\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m \n\u001b[1;32m   1178\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;124;03m        arbitrary code on your machine.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_dangerous_deserialization:\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe de-serialization relies loading a pickle file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1192\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPickle files can be modified to deliver a malicious payload that \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults in execution of arbitrary code on your machine.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou will need to set `allow_dangerous_deserialization` to `True` to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1195\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable deserialization. If you do this, make sure that you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust the source of the data. For example, if you are loading a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile that you created, and know that no one else has modified the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile, then this is safe to do. Do not set this to `True` if you are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1199\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading a file from an untrusted source (e.g., some random site on \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1200\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe internet.).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1201\u001b[0m     )\n\u001b[1;32m   1202\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(folder_path)\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;66;03m# load index separately since it is not picklable\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The de-serialization relies loading a pickle file. Pickle files can be modified to deliver a malicious payload that results in execution of arbitrary code on your machine.You will need to set `allow_dangerous_deserialization` to `True` to enable deserialization. If you do this, make sure that you trust the source of the data. For example, if you are loading a file that you created, and know that no one else has modified the file, then this is safe to do. Do not set this to `True` if you are loading a file from an untrusted source (e.g., some random site on the internet.)."
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import pickle\n",
    "\n",
    "# 1. ë²¡í„° DB ë¡œë“œ\n",
    "embedding = HuggingFaceEmbeddings(model_name='jhgan/ko-sroberta-multitask')\n",
    "db = FAISS.load_local(\"solo_leveling_faiss_ko\", embedding, allow_dangerous_deserialization=True)  # ğŸ”¹ ì´ ì˜µì…˜ ì¶”ê°€\n",
    "\n",
    "\n",
    "# 2. ì˜ˆì‹œ ì§ˆì˜\n",
    "query = \"ì„±ì§„ìš°ëŠ” í™©ë™ì„ê³¼ ì²˜ìŒ ë§Œë‚œ ì¥ë©´ì—ì„œ ë¬´ì—‡ì„ í–ˆì–´?\"\n",
    "docs = db.similarity_search(query, k=3)\n",
    "\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"[{i}] {doc.page_content}\")\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import pickle\n",
    "\n",
    "# 1. ë²¡í„° DB ë¡œë“œ\n",
    "embedding = HuggingFaceEmbeddings(model_name='jhgan/ko-sroberta-multitask')\n",
    "db = FAISS.load_local(\"solo_leveling_faiss_ko\", embedding)\n",
    "\n",
    "# 2. ì˜ˆì‹œ ì§ˆì˜\n",
    "query = \"ì„±ì§„ìš°ëŠ” í™©ë™ì„ê³¼ ì²˜ìŒ ë§Œë‚œ ì¥ë©´ì—ì„œ ë¬´ì—‡ì„ í–ˆì–´?\"\n",
    "docs = db.similarity_search(query, k=3)\n",
    "\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"[{i}] {doc.page_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac05aed2-9dae-4f2f-b3a1-eee03a1f5c81",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error in faiss::FileIOReader::FileIOReader(const char*) at /project/faiss/faiss/impl/io.cpp:67: Error: 'f' failed: could not open solo_leveling_faiss_ko.index for reading: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1084854/3007134425.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 1. ê¸°ì¡´ ë°ì´í„° ë¡œë“œ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mindex_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"solo_leveling_faiss_ko.index\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtexts_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"solo_leveling_texts.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/faiss/swigfaiss_avx512.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m  11640\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11641\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_swigfaiss_avx512\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Error in faiss::FileIOReader::FileIOReader(const char*) at /project/faiss/faiss/impl/io.cpp:67: Error: 'f' failed: could not open solo_leveling_faiss_ko.index for reading: No such file or directory"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.in_memory import InMemoryDocstore\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import faiss\n",
    "import pickle\n",
    "\n",
    "# 1. ê¸°ì¡´ ë°ì´í„° ë¡œë“œ\n",
    "index_path = \"solo_leveling_faiss_ko.index\"\n",
    "texts_path = \"solo_leveling_texts.pkl\"\n",
    "\n",
    "index = faiss.read_index(index_path)\n",
    "with open(texts_path, \"rb\") as f:\n",
    "    texts = pickle.load(f)\n",
    "\n",
    "# 2. ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„\n",
    "embedding = HuggingFaceEmbeddings(model_name='jhgan/ko-sroberta-multitask')\n",
    "\n",
    "# 3. LangChain ë¬¸ì„œí™”\n",
    "docs = [Document(page_content=text) for text in texts]\n",
    "docstore = InMemoryDocstore({str(i): doc for i, doc in enumerate(docs)})\n",
    "index_to_docstore_id = {i: str(i) for i in range(len(docs))}\n",
    "\n",
    "db = FAISS(\n",
    "    embedding_function=embedding,\n",
    "    index=index,\n",
    "    docstore=docstore,\n",
    "    index_to_docstore_id=index_to_docstore_id\n",
    ")\n",
    "\n",
    "# 4. LangChain í˜¸í™˜ êµ¬ì¡°ë¡œ ì €ì¥\n",
    "db.save_local(\"solo_leveling_faiss_langchain\")\n",
    "print(\"ë³€í™˜ ì™„ë£Œ: solo_leveling_faiss_langchain í´ë” ìƒì„±ë¨\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc27fe9f-c69a-4dab-8d9f-603c7079cad6",
   "metadata": {},
   "source": [
    "## 1. tsv full data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60146aa5-f97a-4931-a4f2-7f8d33136f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ì—í”¼ì†Œë“œ                     scene_text  type\n",
      "0  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „    ë„¤, ê¹€ìƒì‹ ì•„ì €ì”¨. ì‹ ê²½ ì¨ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.    ëŒ€ì‚¬\n",
      "1  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „               ë‚´ ì´ë¦„ì€ ì„±ì§„ìš°. Eê¸‰ í—Œí„°  ë‚´ì ì„¤ëª…\n",
      "2  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „         ë­˜ìš” í•˜í•˜... ì˜¤ëŠ˜ë„ ì˜ ë¶€íƒë“œë¦´ê²Œìš”.    ëŒ€ì‚¬\n",
      "3  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „    í—Œí„°í˜‘íšŒ ì†Œì† ì¤‘ ê°€ì¥ ë‚®ì€ ê³„ê¸‰, ìµœì•½ì˜ í—Œí„°.  ë‚´ì ì„¤ëª…\n",
      "4  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „  ì–´? ì•ˆë…•í•˜ì„¸ìš”. ì£¼í¬ ì”¨ë„ ì´ë²ˆ ë ˆì´ë“œ ê°€ì‹œëŠ”êµ°ìš”.    ëŒ€ì‚¬\n",
      "ì „ì²´ ë¬¸ì¥ ìˆ˜: 549\n",
      "ì»¬ëŸ¼ ëª©ë¡: ['ì—í”¼ì†Œë“œ', 'scene_text', 'type']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"sl_webtoon_full_data_sequential.tsv\", sep=\"\\t\")\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "print(\"ì „ì²´ ë¬¸ì¥ ìˆ˜:\", len(df))\n",
    "print(\"ì»¬ëŸ¼ ëª©ë¡:\", df.columns.tolist())\n",
    "\n",
    "# 549\n",
    "#ì—í”¼ì†Œë“œ, scene_text, type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd35b473-3d92-4d9d-a8ee-5565dff05e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ì—í”¼ì†Œë“œ                   scene_text  type\n",
      "0  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „  ë„¤, ê¹€ìƒì‹ ì•„ì €ì”¨. ì‹ ê²½ ì¨ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.    ëŒ€ì‚¬\n",
      "1  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „             ë‚´ ì´ë¦„ì€ ì„±ì§„ìš°. Eê¸‰ í—Œí„°  ë‚´ì ì„¤ëª…\n",
      "2  1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „       ë­˜ìš” í•˜í•˜... ì˜¤ëŠ˜ë„ ì˜ ë¶€íƒë“œë¦´ê²Œìš”.    ëŒ€ì‚¬\n",
      "ì»¬ëŸ¼: ['ì—í”¼ì†Œë“œ', 'scene_text', 'type'] ì „ì²´ í–‰: 549\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"sl_webtoon_full_data_sequential.tsv\", sep=\"\\t\")\n",
    "print(df.head(3))\n",
    "print(\"ì»¬ëŸ¼:\", df.columns.tolist(), \"ì „ì²´ í–‰:\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa5db259-991a-48b1-859f-2308432737c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #0 ëŒ€ì‚¬ ë„¤, ê¹€ìƒì‹ ì•„ì €ì”¨. ì‹ ê²½ ì¨ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.', '[1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #1 ë‚´ì ì„¤ëª… ë‚´ ì´ë¦„ì€ ì„±ì§„ìš°. Eê¸‰ í—Œí„°', '[1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #2 ëŒ€ì‚¬ ë­˜ìš” í•˜í•˜... ì˜¤ëŠ˜ë„ ì˜ ë¶€íƒë“œë¦´ê²Œìš”.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df['row_id'] = df.index #ì¸ë±ìŠ¤ ì»¬ëŸ¼ ì¶”ê°€ <- ì›ë³¸ ì¶”ì ìš©\n",
    "\n",
    "df['text'] = df.apply(\n",
    "    lambda x: f\"[{x['ì—í”¼ì†Œë“œ']}] #{x['row_id']} {x['type']} {x['scene_text']}\", #rag ë¬¸ì¥ ì»¬ëŸ¼ ìƒì„±\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(df['text'].head(3).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b95c977-5485-4fdf-b5d8-fb837a0a8cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìµœì¢… ë¬¸ì¥ ìˆ˜: 549\n"
     ]
    }
   ],
   "source": [
    "texts = df['text'].tolist()\n",
    "print(\"ìµœì¢… ë¬¸ì¥ ìˆ˜:\", len(texts))\n",
    "# 549"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be84111-8a20-49b4-827a-305e9498fe15",
   "metadata": {},
   "source": [
    "## 2. Rag ë¬¸ì¥ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2f948651-c16f-40d6-9b96-2aaafb1d7bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ˆì‹œ 5ê°œ:\n",
      "- [1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #0 ëŒ€ì‚¬ ë„¤, ê¹€ìƒì‹ ì•„ì €ì”¨. ì‹ ê²½ ì¨ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤.\n",
      "- [1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #1 ë‚´ì ì„¤ëª… ë‚´ ì´ë¦„ì€ ì„±ì§„ìš°. Eê¸‰ í—Œí„°\n",
      "- [1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #2 ëŒ€ì‚¬ ë­˜ìš” í•˜í•˜... ì˜¤ëŠ˜ë„ ì˜ ë¶€íƒë“œë¦´ê²Œìš”.\n",
      "- [1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #3 ë‚´ì ì„¤ëª… í—Œí„°í˜‘íšŒ ì†Œì† ì¤‘ ê°€ì¥ ë‚®ì€ ê³„ê¸‰, ìµœì•½ì˜ í—Œí„°.\n",
      "- [1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #4 ëŒ€ì‚¬ ì–´? ì•ˆë…•í•˜ì„¸ìš”. ì£¼í¬ ì”¨ë„ ì´ë²ˆ ë ˆì´ë“œ ê°€ì‹œëŠ”êµ°ìš”.\n",
      "\n",
      "ìµœì¢… ë¬¸ì¥ ìˆ˜: 549\n"
     ]
    }
   ],
   "source": [
    "# 2ë‹¨ê³„: ìµœì¢… RAG ë¬¸ì¥ ìƒì„±\n",
    "df['row_id'] = df.index  # ì›ë³¸ ì¶”ì ìš© ì¸ë±ìŠ¤\n",
    "df['text'] = df.apply(\n",
    "    lambda x: f\"[{x['ì—í”¼ì†Œë“œ']}] #{x['row_id']} {x['type']} {x['scene_text']}\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(\"ì˜ˆì‹œ 5ê°œ:\")\n",
    "for t in df['text'].head(5).tolist():\n",
    "    print(\"-\", t)\n",
    "\n",
    "texts = df['text'].tolist()\n",
    "print(\"\\nìµœì¢… ë¬¸ì¥ ìˆ˜:\", len(texts))\n",
    "#549"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d659a2e-2c7b-4158-b676-d85abc5d3e92",
   "metadata": {},
   "source": [
    "## 3. í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ, ë²¡í„° db - solo_leveling_faiss_ko\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ef1ac89-0931-48a8-9024-26150004b81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ë²¡í„°DB ìƒì„± ì™„ë£Œ. ì´ ë¬¸ì¥ ìˆ˜: 549\n",
      " 'solo_leveling_faiss_ko' í´ë”ì— ì €ì¥\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name='jhgan/ko-sroberta-multitask')\n",
    "\n",
    "db = FAISS.from_texts(texts, embedding_model)\n",
    "print(\" ë²¡í„°DB ìƒì„± ì™„ë£Œ. ì´ ë¬¸ì¥ ìˆ˜:\", len(texts))\n",
    "\n",
    "db.save_local(\"solo_leveling_faiss_ko\")\n",
    "print(\" 'solo_leveling_faiss_ko' í´ë”ì— ì €ì¥\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6acad70-ae02-4808-800e-fee4c2a36153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] [2ê¶Œ_3í™”_í€˜ìŠ¤íŠ¸ ] #332 ëŒ€ì‚¬ ë˜ì „ì— ì‚¬ëŠ” ë§ˆìˆ˜ë¼ë©´ ë§ˆì •ì„ì„ ê°–ê³  ìˆì„ ì¤„ ì•Œì•˜ëŠ”ë°...ì™„ì „íˆ ë‹¤ë¥¸ ë¶€ë¥˜ì¸ê°€.\n",
      "[2] [1ê¶Œ_3í™”_í€˜ìŠ¤íŠ¸] #132 ëŒ€ì‚¬ ì—¬... ì—¬ê¸´?!  ì‚¬ë§‰...!!\n",
      "[3] [2ê¶Œ_3í™”_í€˜ìŠ¤íŠ¸ ] #331 ëŒ€ì‚¬ ì´ ë…€ì„ë“¤ì€ ë§ˆì •ì„ ê°™ì€ ê±´ ì•ˆ ì£¼ë‚˜?\n",
      "[4] [2ê¶Œ_4í™”_ë³´ìŠ¤ì „] #457 ë‚´ì ì„¤ëª… ê²½í—˜ì´ ë§ìœ¼ë©´ ë§ì„ìˆ˜ë¡ ë­í¬ê°€ ë†’ìœ¼ë©´ ë†’ì„ìˆ˜ë¡ ë§ˆìˆ˜ë“¤ì—ê²Œì„œ ë‚˜ì˜¤ëŠ” ë§ˆì •ì„ì€ ê°€ì¹˜ë¥¼ ë”í•´ ê°„ë‹¤.\n",
      "[5] [2ê¶Œ_4í™”_ë³´ìŠ¤ì „] #449 ëŒ€ì‚¬ ë¬¸ì œëŠ” ì§€ëŠ¥ì¸ë°... ë§ˆë²•ê³¼ ê´€ë ¨ëœ ìŠ¤íƒ¯ì¼ ê²ƒ ê°™ê¸´ í•œë°, ì´ê²Œ í”¼ë£¡í• ê¹Œ?\n"
     ]
    }
   ],
   "source": [
    "db = FAISS.load_local(\"solo_leveling_faiss_ko\", embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "#ì˜ˆì‹œ\n",
    "query = \"ë§ˆë‚˜ì„ì´ ë­ì§€?\"\n",
    "docs = db.similarity_search(query, k=5)\n",
    "\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"[{i}] {doc.page_content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b215211a-ed27-4571-a9cf-b5792c6fa20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## rag í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ef2966e-c110-4565-8ddf-1a1bee864934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1139536/3834059051.py:9: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name='jhgan/ko-sroberta-multitask')\n",
      "Device set to use cuda:0\n",
      "/tmp/ipykernel_1139536/3834059051.py:17: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
      "/tmp/ipykernel_1139536/3834059051.py:35: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹µë³€: ë‹¤ìŒ ë¬¸ë§¥ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.\n",
      "\n",
      "ë¬¸ë§¥:\n",
      "[1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #1 ë‚´ì ì„¤ëª… ë‚´ ì´ë¦„ì€ ì„±ì§„ìš°. Eê¸‰ í—Œí„°\n",
      "\n",
      "[2ê¶Œ_4í™”_ë³´ìŠ¤ì „] #451 ëŒ€ì‚¬ í—Œí„° ì„±ì§„ìš°ì…ë‹ˆë‹¤.\n",
      "\n",
      "[1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #9 ë‚´ì ì„¤ëª… Eê¸‰ í—Œí„° ì„±ì§„ìš°.\n",
      "\n",
      "[3ê¶Œ_7í™”_ì´ìƒí•œë ˆì´ë“œ] #484 ë‚´ì ì„¤ëª… ê·¸ ë…€ì„ì´ ì›í•˜ëŠ” ê±´ ì‹¤ë ¥ì€ ìˆì§€ë§Œ ë“±ê¸‰ì´ ë‚®ì€ í—Œí„°ë‹ˆê¹Œ.\n",
      "\n",
      "[2ê¶Œ_4í™”_ë³´ìŠ¤ì „] #468 ë‚´ì ì„¤ëª… ëŠ¥ë ¥ì¹˜ë¥¼ ì˜¬ë¦´ ìˆ˜ ìˆëŠ” í—Œí„°ê°€ ìˆë‹¤?\n",
      "\n",
      "ì§ˆë¬¸:\n",
      "ì„±ì§„ìš°ëŠ” ëª‡ ê¸‰ í—Œí„°ì§€?\n",
      "\n",
      "ë‹µë³€: ì„±ì§„ìš°ëŠ” Eê¸‰ í—Œí„°ì…ë‹ˆë‹¤.  #1 ë‚´ì ì„¤ëª… ë‚´ ì´ë¦„ì€ ì„±ì§„ìš°. Eê¸‰ í—Œí„°  #9 ë‚´ì ì„¤ëª… Eê¸‰ í—Œí„° ì„±ì§„ìš°.  #468 ë‚´ì ì„¤ëª… ëŠ¥ë ¥ì¹˜ë¥¼ ì˜¬ë¦´ ìˆ˜ ìˆëŠ” í—Œí„°ê°€ ìˆë‹¤? ì´ ë¬¸ë§¥ì„ ë³´ë©´ ì„±ì§„ìš°ëŠ” Eê¸‰ í—Œí„°ì…ë‹ˆë‹¤.  ë”°ë¼ì„œ ë‹µì€ Eê¸‰ í—Œí„°ì…ë‹ˆë‹¤.  ì„±ì§„ìš°ëŠ” ëª‡ ê¸‰ í—Œí„°ì§€?  Eê¸‰ í—Œí„°ì…ë‹ˆë‹¤.  ì¦‰, Eê¸‰ì…ë‹ˆë‹¤.  ê·¸ë˜ì„œ ë‹µì€ Eê¸‰ í—Œí„°ì…ë‹ˆë‹¤.  #468 ë‚´ì ì„¤ëª… ëŠ¥ë ¥ì¹˜ë¥¼ ì˜¬ë¦´ ìˆ˜ ìˆëŠ” í—Œí„°ê°€ ìˆë‹¤? ì´ ë¬¸ë§¥ì„ ë³´ë©´ ì„±ì§„ìš°ëŠ” Eê¸‰ í—Œí„°ì…ë‹ˆë‹¤.  ë”°ë¼ì„œ ë‹µì€ Eê¸‰ í—Œí„°ì…ë‹ˆë‹¤.  ì„±ì§„ìš°ëŠ” ëª‡ ê¸‰ í—Œí„°ì§€?  Eê¸‰ í—Œí„°ì…ë‹ˆë‹¤.  ì¦‰, Eê¸‰ì…ë‹ˆë‹¤.  ê·¸ë˜ì„œ ë‹µì€ Eê¸‰ í—Œí„°ì…ë‹ˆë‹¤.  #468 ë‚´ì ì„¤ëª… ëŠ¥ë ¥ì¹˜ë¥¼ ì˜¬ë¦´ ìˆ˜ ìˆëŠ” í—Œí„°ê°€ ìˆë‹¤? ì´ ë¬¸ë§¥ì„ ë³´ë©´ ì„±ì§„ìš°ëŠ” Eê¸‰ í—Œí„°ì…ë‹ˆë‹¤.  ë”°ë¼\n",
      "\n",
      "ì°¸ì¡° ë¬¸ì„œ:\n",
      "[1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #1 ë‚´ì ì„¤ëª… ë‚´ ì´ë¦„ì€ ì„±ì§„ìš°. Eê¸‰ í—Œí„°\n",
      "[2ê¶Œ_4í™”_ë³´ìŠ¤ì „] #451 ëŒ€ì‚¬ í—Œí„° ì„±ì§„ìš°ì…ë‹ˆë‹¤.\n",
      "[1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #9 ë‚´ì ì„¤ëª… Eê¸‰ í—Œí„° ì„±ì§„ìš°.\n",
      "[3ê¶Œ_7í™”_ì´ìƒí•œë ˆì´ë“œ] #484 ë‚´ì ì„¤ëª… ê·¸ ë…€ì„ì´ ì›í•˜ëŠ” ê±´ ì‹¤ë ¥ì€ ìˆì§€ë§Œ ë“±ê¸‰ì´ ë‚®ì€ í—Œí„°ë‹ˆê¹Œ.\n",
      "[2ê¶Œ_4í™”_ë³´ìŠ¤ì „] #468 ë‚´ì ì„¤ëª… ëŠ¥ë ¥ì¹˜ë¥¼ ì˜¬ë¦´ ìˆ˜ ìˆëŠ” í—Œí„°ê°€ ìˆë‹¤?\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name='jhgan/ko-sroberta-multitask')\n",
    "vectorstore = FAISS.load_local(\"solo_leveling_faiss_ko\", embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "model_name = \"kakaocorp/kanana-nano-2.1b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16).to(\"cuda\")\n",
    "\n",
    "llm_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=256)\n",
    "llm = HuggingFacePipeline(pipeline=llm_pipeline)\n",
    "\n",
    "custom_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"ë‹¤ìŒ ë¬¸ë§¥ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.\\n\\në¬¸ë§¥:\\n{context}\\n\\nì§ˆë¬¸:\\n{question}\\n\\në‹µë³€:\"\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 5}),\n",
    "    chain_type=\"stuff\",\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\n",
    "        \"prompt\": custom_prompt  }\n",
    ")\n",
    "\n",
    "#ì§ˆë¬¸\n",
    "query = \"ì„±ì§„ìš°ëŠ” ëª‡ ê¸‰ í—Œí„°ì§€?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(\"ë‹µë³€:\", result[\"result\"])\n",
    "print(\"\\nì°¸ì¡° ë¬¸ì„œ:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(doc.page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10cc72f-d587-4dc3-a6a4-e56b08d0a985",
   "metadata": {},
   "source": [
    "## 4. í™©ë™ì„ ì—í”¼ì†Œë“œ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46946824-27c5-4a95-a293-d6b3ab905277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì„ íƒì§€]\n",
      "1. 1-1. í™©ë™ì„ ë¬´ë¦¬ë¥¼ ëª¨ë‘ ì²˜ì¹˜í•œë‹¤.\n",
      "2. 1-2. í™©ë™ì„ ë¬´ë¦¬ì™€ ì§„í˜¸ë¥¼ í¬í•¨í•˜ì—¬ ëª¨ë‘ ì²˜ì¹˜í•œë‹¤.\n",
      "3. 2. ì ì„ ë¬´ë ¥í™”í•˜ê±°ë‚˜ ê¸°ì ˆì‹œí‚¤ê³  ì‚´ë ¤ë‘”ë‹¤.\n",
      "4. 3-1. ë§ˆì •ì„ì„ ë“¤ê³  ë„ë§ì¹œë‹¤.\n",
      "5. 3-2. ì‹œìŠ¤í…œì„ ê±°ë¶€í•˜ê³  ê·¸ëƒ¥ ë„ë§ì¹œë‹¤.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ì„ íƒ ë²ˆí˜¸ ì…ë ¥:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì‚¬ìš©ì ì„ íƒ]: 2. ì ì„ ë¬´ë ¥í™”í•˜ê±°ë‚˜ ê¸°ì ˆì‹œí‚¤ê³  ì‚´ë ¤ë‘”ë‹¤.\n",
      "\n",
      "[ê²€ìƒ‰ëœ ê·¼ê±° ë¬¸ì„œ ì˜ˆì‹œ]\n",
      "[2ê¶Œ_4í™”_ë³´ìŠ¤ì „] #437 ëŒ€ì‚¬ ë†ˆì˜ ë°©ì–´ë§Œ ë¬´ë ¥í™”ì‹œí‚¬ ìˆ˜ ìˆë‹¤ë©´, í•  ìˆ˜ ìˆë‹¤!\n",
      "[2ê¶Œ_4í™”_ë³´ìŠ¤ì „] #399 ë‚´ì ì„¤ëª… ë™ì‹œì— ì´ë†ˆì˜ ë°©ì–´ë ¥ì„ ë¬´ë ¥í™”ì‹œì¼œì•¼ í•´.\n",
      "[1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #74 ëŒ€ì‚¬ ì§€ê¸ˆ ë‹¹ì¥ì—ë¼ë„ ìš°ë¦¬ë¥¼ ì „ë©¸ì‹œí‚¬ ìˆ˜ ìˆì„ í…ë°... ì™œ ê·¸ëŸ¬ì§€ ì•ŠëŠ” ê±¸ê¹Œìš”?\n",
      "[1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #53 ë‚´ì ì„¤ëª… ì–¸ì œë‚˜ ë§¨ëª¸. ì–´ì°¨í”¼ ì–´ì •ì©¡í•œ ë¬´ê¸°ë¥¼ êµ¬ë§¤í•´ë´¤ì ê¸ˆë°© íŒŒê´´ë  í…Œê³ , ìƒí•´ ë²„ë¦° ëª¸ëš±ì´ ë”°ìœ„, íëŸ¬ë§Œ ìˆë‹¤ë©´ ì–´ì§€ê°„í•œ ì¤‘ìƒì´ ì•„ë‹Œ í•œ ë‚˜ì„ ìˆ˜ ìˆë‹¤.\n",
      "[1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #75 ë‚´ì ì„¤ëª… ì£½ì¼ ìˆ˜ ìˆìŒì—ë„ ì£½ì´ì§€ ì•ŠëŠ”ë‹¤. ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 34\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# 4. ì„±ì§„ìš° ë§íˆ¬ ëŒ€ì‚¬ ìƒì„±\u001b[39;00m\n\u001b[1;32m     24\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124më‹¹ì‹ ì€ ì›¹íˆ° \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124më‚˜ í˜¼ìë§Œ ë ˆë²¨ì—…\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mì˜ ì„±ì§„ìš°ì…ë‹ˆë‹¤.\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124mí˜„ì¬ ìƒí™©:\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124mì„±ì§„ìš°ì˜ ë§íˆ¬ë¡œ ê°„ê²°í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€ì‚¬ë¥¼ 2~3ë¬¸ì¥ ìƒì„±í•˜ì„¸ìš”.\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 34\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m(prompt, \n\u001b[1;32m     35\u001b[0m                      max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120\u001b[39m, \n\u001b[1;32m     36\u001b[0m                      do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     37\u001b[0m                      temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m,\n\u001b[1;32m     38\u001b[0m                      return_full_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# ì¶”ê°€\u001b[39;00m\n\u001b[1;32m     39\u001b[0m )[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[ì„±ì§„ìš° ì‘ë‹µ]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generator' is not defined"
     ]
    }
   ],
   "source": [
    "choices = [\n",
    "    \"1-1. í™©ë™ì„ ë¬´ë¦¬ë¥¼ ëª¨ë‘ ì²˜ì¹˜í•œë‹¤.\",\n",
    "    \"1-2. í™©ë™ì„ ë¬´ë¦¬ì™€ ì§„í˜¸ë¥¼ í¬í•¨í•˜ì—¬ ëª¨ë‘ ì²˜ì¹˜í•œë‹¤.\",\n",
    "    \"2. ì ì„ ë¬´ë ¥í™”í•˜ê±°ë‚˜ ê¸°ì ˆì‹œí‚¤ê³  ì‚´ë ¤ë‘”ë‹¤.\",\n",
    "    \"3-1. ë§ˆì •ì„ì„ ë“¤ê³  ë„ë§ì¹œë‹¤.\",\n",
    "    \"3-2. ì‹œìŠ¤í…œì„ ê±°ë¶€í•˜ê³  ê·¸ëƒ¥ ë„ë§ì¹œë‹¤.\"\n",
    "]\n",
    "\n",
    "print(\"\\n[ì„ íƒì§€]\")\n",
    "for idx, choice in enumerate(choices, start=1):\n",
    "    print(f\"{idx}. {choice}\")\n",
    "\n",
    "user_idx = int(input(\"\\nì„ íƒ ë²ˆí˜¸ ì…ë ¥: \")) - 1\n",
    "user_choice = choices[user_idx]\n",
    "print(f\"\\n[ì‚¬ìš©ì ì„ íƒ]: {user_choice}\")\n",
    "\n",
    "result = qa_chain({\"query\": user_choice})\n",
    "\n",
    "retrieved_context = \"\\n\".join([doc.page_content for doc in result[\"source_documents\"]])\n",
    "print(\"\\n[ê²€ìƒ‰ëœ ê·¼ê±° ë¬¸ì„œ ì˜ˆì‹œ]\")\n",
    "print(retrieved_context[:600], \"...\")  # ê¸¸ë©´ ì¼ë¶€ë§Œ ì¶œë ¥\n",
    "\n",
    "# 4. ì„±ì§„ìš° ë§íˆ¬ ëŒ€ì‚¬ ìƒì„±\n",
    "prompt = f\"\"\"\n",
    "ë‹¹ì‹ ì€ ì›¹íˆ° 'ë‚˜ í˜¼ìë§Œ ë ˆë²¨ì—…'ì˜ ì„±ì§„ìš°ì…ë‹ˆë‹¤.\n",
    "í˜„ì¬ ìƒí™©:\n",
    "{retrieved_context}\n",
    "\n",
    "ì‚¬ìš©ì ì„ íƒ: {user_choice}\n",
    "\n",
    "ì„±ì§„ìš°ì˜ ë§íˆ¬ë¡œ ê°„ê²°í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€ì‚¬ë¥¼ 2~3ë¬¸ì¥ ìƒì„±í•˜ì„¸ìš”.\n",
    "\"\"\"\n",
    "\n",
    "response = generator(prompt, \n",
    "                     max_new_tokens=120, \n",
    "                     do_sample=True, \n",
    "                     temperature=0.7,\n",
    "                     return_full_text=False  # ì¶”ê°€\n",
    ")[0][\"generated_text\"]\n",
    "print(\"\\n[ì„±ì§„ìš° ì‘ë‹µ]\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96472704-01d4-42e2-8649-4857a53ca1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ì—í”¼ì†Œë“œëª…', 'ëŒ€ì‚¬', 'ë‚´ì ì„¤ëª…', 'ì‹œìŠ¤í…œ']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ade26ea-72b5-4a06-a1d1-be209235833d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì„ íƒì§€]\n",
      "1. 1-1. í™©ë™ì„ ë¬´ë¦¬ë¥¼ ëª¨ë‘ ì²˜ì¹˜í•œë‹¤.\n",
      "2. 1-2. í™©ë™ì„ ë¬´ë¦¬ì™€ ì§„í˜¸ë¥¼ í¬í•¨í•˜ì—¬ ëª¨ë‘ ì²˜ì¹˜í•œë‹¤.\n",
      "3. 2. ì ì„ ë¬´ë ¥í™”í•˜ê±°ë‚˜ ê¸°ì ˆì‹œí‚¤ê³  ì‚´ë ¤ë‘”ë‹¤.\n",
      "4. 3-1. ë§ˆì •ì„ì„ ë“¤ê³  ë„ë§ì¹œë‹¤.\n",
      "5. 3-2. ì‹œìŠ¤í…œì„ ê±°ë¶€í•˜ê³  ê·¸ëƒ¥ ë„ë§ì¹œë‹¤.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ì„ íƒ ë²ˆí˜¸ ì…ë ¥:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì‚¬ìš©ì ì„ íƒ]: 2. ì ì„ ë¬´ë ¥í™”í•˜ê±°ë‚˜ ê¸°ì ˆì‹œí‚¤ê³  ì‚´ë ¤ë‘”ë‹¤.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'qa_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m user_choice \u001b[38;5;241m=\u001b[39m choices[user_idx]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[ì‚¬ìš©ì ì„ íƒ]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_choice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mqa_chain\u001b[49m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_choice})\n\u001b[1;32m     19\u001b[0m retrieved_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_documents\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[ê²€ìƒ‰ëœ ê·¼ê±° ë¬¸ì„œ ì˜ˆì‹œ]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'qa_chain' is not defined"
     ]
    }
   ],
   "source": [
    "choices = [\n",
    "    \"1-1. í™©ë™ì„ ë¬´ë¦¬ë¥¼ ëª¨ë‘ ì²˜ì¹˜í•œë‹¤.\",\n",
    "    \"1-2. í™©ë™ì„ ë¬´ë¦¬ì™€ ì§„í˜¸ë¥¼ í¬í•¨í•˜ì—¬ ëª¨ë‘ ì²˜ì¹˜í•œë‹¤.\",\n",
    "    \"2. ì ì„ ë¬´ë ¥í™”í•˜ê±°ë‚˜ ê¸°ì ˆì‹œí‚¤ê³  ì‚´ë ¤ë‘”ë‹¤.\",\n",
    "    \"3-1. ë§ˆì •ì„ì„ ë“¤ê³  ë„ë§ì¹œë‹¤.\",\n",
    "    \"3-2. ì‹œìŠ¤í…œì„ ê±°ë¶€í•˜ê³  ê·¸ëƒ¥ ë„ë§ì¹œë‹¤.\"\n",
    "]\n",
    "\n",
    "print(\"\\n[ì„ íƒì§€]\")\n",
    "for idx, choice in enumerate(choices, start=1):\n",
    "    print(f\"{idx}. {choice}\")\n",
    "\n",
    "user_idx = int(input(\"\\nì„ íƒ ë²ˆí˜¸ ì…ë ¥: \")) - 1\n",
    "user_choice = choices[user_idx]\n",
    "print(f\"\\n[ì‚¬ìš©ì ì„ íƒ]: {user_choice}\")\n",
    "\n",
    "result = qa_chain({\"query\": user_choice})\n",
    "\n",
    "retrieved_context = \"\\n\".join([doc.page_content for doc in result[\"source_documents\"]])\n",
    "print(\"\\n[ê²€ìƒ‰ëœ ê·¼ê±° ë¬¸ì„œ ì˜ˆì‹œ]\")\n",
    "print(retrieved_context[:600], \"...\")  # ê¸¸ë©´ ì¼ë¶€ë§Œ ì¶œë ¥\n",
    "\n",
    "# 4. ì„±ì§„ìš° ë§íˆ¬ ëŒ€ì‚¬ ìƒì„±\n",
    "prompt = f\"\"\"\n",
    "ë‹¹ì‹ ì€ ì›¹íˆ° 'ë‚˜ í˜¼ìë§Œ ë ˆë²¨ì—…'ì˜ ì„±ì§„ìš°ì…ë‹ˆë‹¤.\n",
    "í˜„ì¬ ìƒí™©:\n",
    "{retrieved_context}\n",
    "\n",
    "ì‚¬ìš©ì ì„ íƒ: {user_choice}\n",
    "\n",
    "ì„±ì§„ìš°ì˜ ë§íˆ¬ë¡œ ê°„ê²°í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€ì‚¬ë¥¼ 2~3ë¬¸ì¥ ìƒì„±í•˜ì„¸ìš”.\n",
    "\"\"\"\n",
    "\n",
    "response = generator(prompt, max_new_tokens=120, do_sample=True, temperature=0.7)[0][\"generated_text\"]\n",
    "print(\"\\n[ì„±ì§„ìš° ì‘ë‹µ]\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39c1f4a7-64fb-4e5d-9658-e761177b97c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì„ íƒì§€]\n",
      "1. 1-1. í™©ë™ì„ ë¬´ë¦¬ë¥¼ ëª¨ë‘ ì²˜ì¹˜í•œë‹¤.\n",
      "2. 1-2. í™©ë™ì„ ë¬´ë¦¬ì™€ ì§„í˜¸ë¥¼ í¬í•¨í•˜ì—¬ ëª¨ë‘ ì²˜ì¹˜í•œë‹¤.\n",
      "3. 2. ì ì„ ë¬´ë ¥í™”í•˜ê±°ë‚˜ ê¸°ì ˆì‹œí‚¤ê³  ì‚´ë ¤ë‘”ë‹¤.\n",
      "4. 3-1. ë§ˆì •ì„ì„ ë“¤ê³  ë„ë§ì¹œë‹¤.\n",
      "5. 3-2. ì‹œìŠ¤í…œì„ ê±°ë¶€í•˜ê³  ê·¸ëƒ¥ ë„ë§ì¹œë‹¤.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "ì„ íƒ ë²ˆí˜¸ ì…ë ¥:  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ì‚¬ìš©ì ì„ íƒ]: 2. ì ì„ ë¬´ë ¥í™”í•˜ê±°ë‚˜ ê¸°ì ˆì‹œí‚¤ê³  ì‚´ë ¤ë‘”ë‹¤.\n",
      "\n",
      "[ê²€ìƒ‰ëœ ê·¼ê±° ë¬¸ì„œ ì˜ˆì‹œ]\n",
      "[2ê¶Œ_4í™”_ë³´ìŠ¤ì „] #437 ëŒ€ì‚¬ ë†ˆì˜ ë°©ì–´ë§Œ ë¬´ë ¥í™”ì‹œí‚¬ ìˆ˜ ìˆë‹¤ë©´, í•  ìˆ˜ ìˆë‹¤!\n",
      "[2ê¶Œ_4í™”_ë³´ìŠ¤ì „] #399 ë‚´ì ì„¤ëª… ë™ì‹œì— ì´ë†ˆì˜ ë°©ì–´ë ¥ì„ ë¬´ë ¥í™”ì‹œì¼œì•¼ í•´.\n",
      "[1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #74 ëŒ€ì‚¬ ì§€ê¸ˆ ë‹¹ì¥ì—ë¼ë„ ìš°ë¦¬ë¥¼ ì „ë©¸ì‹œí‚¬ ìˆ˜ ìˆì„ í…ë°... ì™œ ê·¸ëŸ¬ì§€ ì•ŠëŠ” ê±¸ê¹Œìš”?\n",
      "[1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #53 ë‚´ì ì„¤ëª… ì–¸ì œë‚˜ ë§¨ëª¸. ì–´ì°¨í”¼ ì–´ì •ì©¡í•œ ë¬´ê¸°ë¥¼ êµ¬ë§¤í•´ë´¤ì ê¸ˆë°© íŒŒê´´ë  í…Œê³ , ìƒí•´ ë²„ë¦° ëª¸ëš±ì´ ë”°ìœ„, íëŸ¬ë§Œ ìˆë‹¤ë©´ ì–´ì§€ê°„í•œ ì¤‘ìƒì´ ì•„ë‹Œ í•œ ë‚˜ì„ ìˆ˜ ìˆë‹¤.\n",
      "[1ê¶Œ_1í™”_ì´ì¤‘ë˜ì „] #75 ë‚´ì ì„¤ëª… ì£½ì¼ ìˆ˜ ìˆìŒì—ë„ ì£½ì´ì§€ ì•ŠëŠ”ë‹¤. ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 34\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# 4. ì„±ì§„ìš° ë§íˆ¬ ëŒ€ì‚¬ ìƒì„±\u001b[39;00m\n\u001b[1;32m     24\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124më‹¹ì‹ ì€ ì›¹íˆ° \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124më‚˜ í˜¼ìë§Œ ë ˆë²¨ì—…\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mì˜ ì„±ì§„ìš°ì…ë‹ˆë‹¤.\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124mí˜„ì¬ ìƒí™©:\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124mì„±ì§„ìš°ì˜ ë§íˆ¬ë¡œ ê°„ê²°í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€ì‚¬ë¥¼ 2~3ë¬¸ì¥ ìƒì„±í•˜ì„¸ìš”.\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 34\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerator\u001b[49m(prompt, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120\u001b[39m, do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[ì„±ì§„ìš° ì‘ë‹µ]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generator' is not defined"
     ]
    }
   ],
   "source": [
    "choices = [\n",
    "    \"1-1. í™©ë™ì„ ë¬´ë¦¬ë¥¼ ëª¨ë‘ ì²˜ì¹˜í•œë‹¤.\",\n",
    "    \"1-2. í™©ë™ì„ ë¬´ë¦¬ì™€ ì§„í˜¸ë¥¼ í¬í•¨í•˜ì—¬ ëª¨ë‘ ì²˜ì¹˜í•œë‹¤.\",\n",
    "    \"2. ì ì„ ë¬´ë ¥í™”í•˜ê±°ë‚˜ ê¸°ì ˆì‹œí‚¤ê³  ì‚´ë ¤ë‘”ë‹¤.\",\n",
    "    \"3-1. ë§ˆì •ì„ì„ ë“¤ê³  ë„ë§ì¹œë‹¤.\",\n",
    "    \"3-2. ì‹œìŠ¤í…œì„ ê±°ë¶€í•˜ê³  ê·¸ëƒ¥ ë„ë§ì¹œë‹¤.\"\n",
    "]\n",
    "\n",
    "print(\"\\n[ì„ íƒì§€]\")\n",
    "for idx, choice in enumerate(choices, start=1):\n",
    "    print(f\"{idx}. {choice}\")\n",
    "\n",
    "user_idx = int(input(\"\\nì„ íƒ ë²ˆí˜¸ ì…ë ¥: \")) - 1\n",
    "user_choice = choices[user_idx]\n",
    "print(f\"\\n[ì‚¬ìš©ì ì„ íƒ]: {user_choice}\")\n",
    "\n",
    "result = qa_chain({\"query\": user_choice})\n",
    "\n",
    "retrieved_context = \"\\n\".join([doc.page_content for doc in result[\"source_documents\"]])\n",
    "print(\"\\n[ê²€ìƒ‰ëœ ê·¼ê±° ë¬¸ì„œ ì˜ˆì‹œ]\")\n",
    "print(retrieved_context[:600], \"...\")  # ê¸¸ë©´ ì¼ë¶€ë§Œ ì¶œë ¥\n",
    "\n",
    "# 4. ì„±ì§„ìš° ë§íˆ¬ ëŒ€ì‚¬ ìƒì„±\n",
    "prompt = f\"\"\"\n",
    "ë‹¹ì‹ ì€ ì›¹íˆ° 'ë‚˜ í˜¼ìë§Œ ë ˆë²¨ì—…'ì˜ ì„±ì§„ìš°ì…ë‹ˆë‹¤.\n",
    "í˜„ì¬ ìƒí™©:\n",
    "{retrieved_context}\n",
    "\n",
    "ì‚¬ìš©ì ì„ íƒ: {user_choice}\n",
    "\n",
    "ì„±ì§„ìš°ì˜ ë§íˆ¬ë¡œ ê°„ê²°í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€ì‚¬ë¥¼ 2~3ë¬¸ì¥ ìƒì„±í•˜ì„¸ìš”.\n",
    "\"\"\"\n",
    "\n",
    "response = generator(prompt, max_new_tokens=120, do_sample=True, temperature=0.7)[0][\"generated_text\"]\n",
    "print(\"\\n[ì„±ì§„ìš° ì‘ë‹µ]\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b0ff96-158d-4b60-a3fe-e6d54ba00afd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ka)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
